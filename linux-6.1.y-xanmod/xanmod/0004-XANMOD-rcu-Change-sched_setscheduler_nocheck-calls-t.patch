From 2230bc7ea704917d3674a9b4ae7c8e47d7f204d6 Mon Sep 17 00:00:00 2001
From: Alexandre Frade <kernel@xanmod.org>
Date: Wed, 5 Oct 2022 03:46:34 +0000
Subject: [PATCH 04/16] XANMOD: rcu: Change sched_setscheduler_nocheck() calls to
 SCHED_RR policy

Signed-off-by: Alexandre Frade <kernel@xanmod.org>
---
 Documentation/admin-guide/kernel-parameters.txt | 2 +-
 kernel/rcu/Kconfig                              | 4 ++--
 kernel/rcu/rcutorture.c                         | 2 +-
 kernel/rcu/tree.c                               | 6 +++---
 kernel/rcu/tree_nocb.h                          | 4 ++--
 kernel/rcu/tree_plugin.h                        | 4 ++--
 6 files changed, 11 insertions(+), 11 deletions(-)

diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt
index ed9b8e7c2d83..2fe1f0f67ada 100644
--- a/Documentation/admin-guide/kernel-parameters.txt
+++ b/Documentation/admin-guide/kernel-parameters.txt
@@ -4710,7 +4710,7 @@
			overwritten.

	rcutree.kthread_prio= 	 [KNL,BOOT]
-			Set the SCHED_FIFO priority of the RCU per-CPU
+			Set the SCHED_RR priority of the RCU per-CPU
			kthreads (rcuc/N). This value is also used for
			the priority of the RCU boost threads (rcub/N)
			and for the RCU grace-period kthreads (rcu_bh,
diff --git a/kernel/rcu/Kconfig b/kernel/rcu/Kconfig
index d471d22a5e21..e945e522969e 100644
--- a/kernel/rcu/Kconfig
+++ b/kernel/rcu/Kconfig
@@ -282,9 +282,9 @@ config RCU_NOCB_CPU_CB_BOOST
	depends on RCU_NOCB_CPU && RCU_BOOST
	default y if PREEMPT_RT
	help
-	  Use this option to invoke offloaded callbacks as SCHED_FIFO
+	  Use this option to invoke offloaded callbacks as SCHED_RR
	  to avoid starvation by heavy SCHED_OTHER background load.
-	  Of course, running as SCHED_FIFO during callback floods will
+	  Of course, running as SCHED_RR during callback floods will
	  cause the rcuo[ps] kthreads to monopolize the CPU for hundreds
	  of milliseconds or more.  Therefore, when enabling this option,
	  it is your responsibility to ensure that latency-sensitive
diff --git a/kernel/rcu/rcutorture.c b/kernel/rcu/rcutorture.c
index d8e1b270a065..c543c348e7c0 100644
--- a/kernel/rcu/rcutorture.c
+++ b/kernel/rcu/rcutorture.c
@@ -2156,7 +2156,7 @@ static int rcutorture_booster_init(unsigned int cpu)
		t = per_cpu(ksoftirqd, cpu);
		WARN_ON_ONCE(!t);
		sp.sched_priority = 2;
-		sched_setscheduler_nocheck(t, SCHED_FIFO, &sp);
+		sched_setscheduler_nocheck(t, SCHED_RR, &sp);
	}

	/* Don't allow time recalculation while creating a new task. */
diff --git a/kernel/rcu/tree.c b/kernel/rcu/tree.c
index 79aea7df4345..97a491ee03b3 100644
--- a/kernel/rcu/tree.c
+++ b/kernel/rcu/tree.c
@@ -4236,8 +4236,8 @@ static void __init rcu_start_exp_gp_kworkers(void)
		return;
	}

-	sched_setscheduler_nocheck(rcu_exp_gp_kworker->task, SCHED_FIFO, &param);
-	sched_setscheduler_nocheck(rcu_exp_par_gp_kworker->task, SCHED_FIFO,
+	sched_setscheduler_nocheck(rcu_exp_gp_kworker->task, SCHED_RR, &param);
+	sched_setscheduler_nocheck(rcu_exp_par_gp_kworker->task, SCHED_RR,
				   &param);
 }

@@ -4275,7 +4275,7 @@ static int __init rcu_spawn_gp_kthread(void)
		return 0;
	if (kthread_prio) {
		sp.sched_priority = kthread_prio;
-		sched_setscheduler_nocheck(t, SCHED_FIFO, &sp);
+		sched_setscheduler_nocheck(t, SCHED_RR, &sp);
	}
	rnp = rcu_get_root();
	raw_spin_lock_irqsave_rcu_node(rnp, flags);
diff --git a/kernel/rcu/tree_nocb.h b/kernel/rcu/tree_nocb.h
index a8f574d8850d..34325fbc0cf0 100644
--- a/kernel/rcu/tree_nocb.h
+++ b/kernel/rcu/tree_nocb.h
@@ -1319,7 +1319,7 @@ static void rcu_spawn_cpu_nocb_kthread(int cpu)
		}
		WRITE_ONCE(rdp_gp->nocb_gp_kthread, t);
		if (kthread_prio)
-			sched_setscheduler_nocheck(t, SCHED_FIFO, &sp);
+			sched_setscheduler_nocheck(t, SCHED_RR, &sp);
	}
	mutex_unlock(&rdp_gp->nocb_gp_kthread_mutex);

@@ -1330,7 +1330,7 @@ static void rcu_spawn_cpu_nocb_kthread(int cpu)
		goto end;

	if (IS_ENABLED(CONFIG_RCU_NOCB_CPU_CB_BOOST) && kthread_prio)
-		sched_setscheduler_nocheck(t, SCHED_FIFO, &sp);
+		sched_setscheduler_nocheck(t, SCHED_RR, &sp);

	WRITE_ONCE(rdp->nocb_cb_kthread, t);
	WRITE_ONCE(rdp->nocb_gp_kthread, rdp_gp->nocb_gp_kthread);
diff --git a/kernel/rcu/tree_plugin.h b/kernel/rcu/tree_plugin.h
index 438ecae6bd7e..518c05213198 100644
--- a/kernel/rcu/tree_plugin.h
+++ b/kernel/rcu/tree_plugin.h
@@ -1006,7 +1006,7 @@ static void rcu_cpu_kthread_setup(unsigned int cpu)
	struct sched_param sp;

	sp.sched_priority = kthread_prio;
-	sched_setscheduler_nocheck(current, SCHED_FIFO, &sp);
+	sched_setscheduler_nocheck(current, SCHED_RR, &sp);
 #endif /* #ifdef CONFIG_RCU_BOOST */

	WRITE_ONCE(rdp->rcuc_activity, jiffies);
@@ -1205,7 +1205,7 @@ static void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)
	rnp->boost_kthread_task = t;
	raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
	sp.sched_priority = kthread_prio;
-	sched_setscheduler_nocheck(t, SCHED_FIFO, &sp);
+	sched_setscheduler_nocheck(t, SCHED_RR, &sp);
	wake_up_process(t); /* get to TASK_INTERRUPTIBLE quickly. */

  out:
--
2.35.1
